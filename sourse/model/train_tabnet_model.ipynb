{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"772bpfcapLDK"},"outputs":[],"source":["from pytorch_tabnet.tab_model import TabNetClassifier\n","import numpy as np\n","import pandas as pd\n","\n","train_data = pd.read_csv(\"train_set.csv\", index_col=None)\n","test_data = pd.read_csv(\"test_set.csv\", index_col=None)\n","\n","X_train = train_data.drop(columns=\"truth\")\n","y_train = train_data[['truth']]\n","\n","X_test = test_data.drop(columns=\"truth\")\n","y_test = test_data[['truth']]\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-juXGM7YpLDL","outputId":"ce04184b-83e6-40db-81ec-f8475758cf18"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>gender</th>\n","      <th>education</th>\n","      <th>age</th>\n","      <th>prev_dropout_num</th>\n","      <th>previous_enroll_num</th>\n","      <th>previous_dropout_user_num</th>\n","      <th>duration</th>\n","      <th>session_num</th>\n","      <th>video_num</th>\n","      <th>courseware_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>8</td>\n","      <td>128</td>\n","      <td>1</td>\n","      <td>29</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>67</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>25.0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>112</td>\n","      <td>1</td>\n","      <td>26</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>18.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>112</td>\n","      <td>1</td>\n","      <td>71</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>18.0</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>128</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>157938</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>29.0</td>\n","      <td>2</td>\n","      <td>369</td>\n","      <td>331</td>\n","      <td>71</td>\n","      <td>7</td>\n","      <td>941</td>\n","      <td>82</td>\n","    </tr>\n","    <tr>\n","      <th>157939</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>53.0</td>\n","      <td>15</td>\n","      <td>367</td>\n","      <td>331</td>\n","      <td>71</td>\n","      <td>12</td>\n","      <td>370</td>\n","      <td>168</td>\n","    </tr>\n","    <tr>\n","      <th>157940</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>24.0</td>\n","      <td>0</td>\n","      <td>377</td>\n","      <td>336</td>\n","      <td>71</td>\n","      <td>9</td>\n","      <td>930</td>\n","      <td>532</td>\n","    </tr>\n","    <tr>\n","      <th>157941</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>23.0</td>\n","      <td>0</td>\n","      <td>379</td>\n","      <td>336</td>\n","      <td>71</td>\n","      <td>14</td>\n","      <td>369</td>\n","      <td>370</td>\n","    </tr>\n","    <tr>\n","      <th>157942</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20.0</td>\n","      <td>1</td>\n","      <td>378</td>\n","      <td>336</td>\n","      <td>71</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>157943 rows × 10 columns</p>\n","</div>"],"text/plain":["        gender  education   age  prev_dropout_num  previous_enroll_num  \\\n","0            1          0  27.0                 0                   12   \n","1            0          0  26.0                 0                    6   \n","2            1          0  25.0                 0                    5   \n","3            1          0  18.0                 0                    0   \n","4            0          4  18.0                 0                    7   \n","...        ...        ...   ...               ...                  ...   \n","157938       1          1  29.0                 2                  369   \n","157939       0          0  53.0                15                  367   \n","157940       1          0  24.0                 0                  377   \n","157941       0          2  23.0                 0                  379   \n","157942       0          0  20.0                 1                  378   \n","\n","        previous_dropout_user_num  duration  session_num  video_num  \\\n","0                               8       128            1         29   \n","1                               5        67            1          6   \n","2                               5       112            1         26   \n","3                               0       112            1         71   \n","4                               4       128            1          5   \n","...                           ...       ...          ...        ...   \n","157938                        331        71            7        941   \n","157939                        331        71           12        370   \n","157940                        336        71            9        930   \n","157941                        336        71           14        369   \n","157942                        336        71            3          4   \n","\n","        courseware_num  \n","0                    1  \n","1                    3  \n","2                    5  \n","3                    2  \n","4                    1  \n","...                ...  \n","157938              82  \n","157939             168  \n","157940             532  \n","157941             370  \n","157942               9  \n","\n","[157943 rows x 10 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["X_train.drop(columns=['Unnamed: 0', 'enroll_id'], inplace=True)\n","X_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WmKr_z_ApLDM"},"outputs":[],"source":["X_test.drop(columns=['Unnamed: 0', 'enroll_id'], inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FDAW-qkipLDM","outputId":"618e3fc2-4120-427c-c490-eb4928dee389"},"outputs":[{"data":{"text/plain":["array([1, 1, 0, ..., 0, 0, 0])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["y_train.values.ravel()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Hv-vQqwpLDM","outputId":"e63834f5-c53a-401a-e87a-094e28793490"},"outputs":[{"data":{"text/plain":["array([ 1.,  0., 27., ...,  3.,  4.,  9.])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["X_train.values.ravel()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RFnj3Hx_pLDM","outputId":"948f1cf6-3a89-4108-d95b-d35bd8cb2d0c"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\baolo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n","c:\\Users\\baolo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n","  warnings.warn(wrn_msg)\n"]},{"name":"stdout","output_type":"stream","text":["epoch 0  | loss: 0.42309 |  0:00:04s\n","epoch 1  | loss: 0.3965  |  0:00:07s\n","epoch 2  | loss: 0.39046 |  0:00:11s\n","epoch 3  | loss: 0.38277 |  0:00:15s\n","epoch 4  | loss: 0.37789 |  0:00:19s\n","epoch 5  | loss: 0.37504 |  0:00:23s\n","epoch 6  | loss: 0.37291 |  0:00:27s\n","epoch 7  | loss: 0.37119 |  0:00:31s\n","epoch 8  | loss: 0.37133 |  0:00:35s\n","epoch 9  | loss: 0.3686  |  0:00:39s\n","epoch 10 | loss: 0.36592 |  0:00:43s\n","epoch 11 | loss: 0.36605 |  0:00:47s\n","epoch 12 | loss: 0.3656  |  0:00:51s\n","epoch 13 | loss: 0.36467 |  0:00:55s\n","epoch 14 | loss: 0.36433 |  0:00:59s\n","epoch 15 | loss: 0.36276 |  0:01:03s\n","epoch 16 | loss: 0.36329 |  0:01:07s\n","epoch 17 | loss: 0.36388 |  0:01:11s\n","epoch 18 | loss: 0.36265 |  0:01:14s\n","epoch 19 | loss: 0.36232 |  0:01:18s\n","epoch 20 | loss: 0.36242 |  0:01:22s\n","epoch 21 | loss: 0.36247 |  0:01:26s\n","epoch 22 | loss: 0.36167 |  0:01:30s\n","epoch 23 | loss: 0.36127 |  0:01:34s\n","epoch 24 | loss: 0.36086 |  0:01:38s\n","epoch 25 | loss: 0.36559 |  0:01:42s\n","epoch 26 | loss: 0.36312 |  0:01:46s\n","epoch 27 | loss: 0.36145 |  0:01:50s\n","epoch 28 | loss: 0.36161 |  0:01:54s\n","epoch 29 | loss: 0.36159 |  0:01:58s\n","epoch 30 | loss: 0.3604  |  0:02:02s\n","epoch 31 | loss: 0.35976 |  0:02:06s\n","epoch 32 | loss: 0.36013 |  0:02:10s\n","epoch 33 | loss: 0.35939 |  0:02:14s\n","epoch 34 | loss: 0.35979 |  0:02:18s\n","epoch 35 | loss: 0.35986 |  0:02:22s\n","epoch 36 | loss: 0.35953 |  0:02:26s\n","epoch 37 | loss: 0.35923 |  0:02:31s\n","epoch 38 | loss: 0.35918 |  0:02:35s\n","epoch 39 | loss: 0.35891 |  0:02:39s\n","epoch 40 | loss: 0.35885 |  0:02:43s\n","epoch 41 | loss: 0.35908 |  0:02:47s\n","epoch 42 | loss: 0.35851 |  0:02:51s\n","epoch 43 | loss: 0.35939 |  0:02:55s\n","epoch 44 | loss: 0.35879 |  0:03:00s\n","epoch 45 | loss: 0.35935 |  0:03:04s\n","epoch 46 | loss: 0.35897 |  0:03:08s\n","epoch 47 | loss: 0.35864 |  0:03:12s\n","epoch 48 | loss: 0.35881 |  0:03:16s\n","epoch 49 | loss: 0.35882 |  0:03:20s\n","epoch 50 | loss: 0.3586  |  0:03:24s\n","epoch 51 | loss: 0.35934 |  0:03:28s\n","epoch 52 | loss: 0.35858 |  0:03:32s\n","epoch 53 | loss: 0.35899 |  0:03:37s\n","epoch 54 | loss: 0.3585  |  0:03:41s\n","epoch 55 | loss: 0.35885 |  0:03:45s\n","epoch 56 | loss: 0.35886 |  0:03:49s\n","epoch 57 | loss: 0.35847 |  0:03:53s\n","epoch 58 | loss: 0.35838 |  0:03:56s\n","epoch 59 | loss: 0.35775 |  0:04:00s\n","epoch 60 | loss: 0.35841 |  0:04:04s\n","epoch 61 | loss: 0.35891 |  0:04:08s\n","epoch 62 | loss: 0.35775 |  0:04:12s\n","epoch 63 | loss: 0.35836 |  0:04:16s\n","epoch 64 | loss: 0.35781 |  0:04:20s\n","epoch 65 | loss: 0.35763 |  0:04:24s\n","epoch 66 | loss: 0.35786 |  0:04:28s\n","epoch 67 | loss: 0.35758 |  0:04:32s\n","epoch 68 | loss: 0.35794 |  0:04:36s\n","epoch 69 | loss: 0.35708 |  0:04:40s\n","epoch 70 | loss: 0.35841 |  0:04:44s\n","epoch 71 | loss: 0.35745 |  0:04:48s\n","epoch 72 | loss: 0.35786 |  0:04:52s\n","epoch 73 | loss: 0.35779 |  0:04:55s\n","epoch 74 | loss: 0.35696 |  0:04:59s\n","epoch 75 | loss: 0.35771 |  0:05:03s\n","epoch 76 | loss: 0.35677 |  0:05:07s\n","epoch 77 | loss: 0.35706 |  0:05:11s\n","epoch 78 | loss: 0.3567  |  0:05:15s\n","epoch 79 | loss: 0.35683 |  0:05:19s\n","epoch 80 | loss: 0.35773 |  0:05:23s\n","epoch 81 | loss: 0.357   |  0:05:27s\n","epoch 82 | loss: 0.3568  |  0:05:31s\n","epoch 83 | loss: 0.35661 |  0:05:35s\n","epoch 84 | loss: 0.35667 |  0:05:40s\n","epoch 85 | loss: 0.35711 |  0:05:44s\n","epoch 86 | loss: 0.3565  |  0:05:48s\n","epoch 87 | loss: 0.3567  |  0:05:54s\n","epoch 88 | loss: 0.35667 |  0:06:00s\n","epoch 89 | loss: 0.35645 |  0:06:06s\n","epoch 90 | loss: 0.35688 |  0:06:11s\n","epoch 91 | loss: 0.35662 |  0:06:16s\n","epoch 92 | loss: 0.35697 |  0:06:22s\n","epoch 93 | loss: 0.35654 |  0:06:28s\n","epoch 94 | loss: 0.3564  |  0:06:33s\n","epoch 95 | loss: 0.35633 |  0:06:37s\n","epoch 96 | loss: 0.35634 |  0:06:41s\n","epoch 97 | loss: 0.35624 |  0:06:45s\n","epoch 98 | loss: 0.35621 |  0:06:49s\n","epoch 99 | loss: 0.35616 |  0:06:53s\n","epoch 100| loss: 0.35592 |  0:06:57s\n","epoch 101| loss: 0.35577 |  0:07:01s\n","epoch 102| loss: 0.35572 |  0:07:05s\n","epoch 103| loss: 0.35729 |  0:07:09s\n","epoch 104| loss: 0.35612 |  0:07:14s\n","epoch 105| loss: 0.35599 |  0:07:19s\n","epoch 106| loss: 0.35597 |  0:07:23s\n","epoch 107| loss: 0.3557  |  0:07:27s\n","epoch 108| loss: 0.35576 |  0:07:31s\n","epoch 109| loss: 0.35574 |  0:07:36s\n","epoch 110| loss: 0.35519 |  0:07:40s\n","epoch 111| loss: 0.35478 |  0:07:44s\n","epoch 112| loss: 0.3558  |  0:07:48s\n","epoch 113| loss: 0.35548 |  0:07:52s\n","epoch 114| loss: 0.35498 |  0:07:56s\n","epoch 115| loss: 0.35537 |  0:08:02s\n","epoch 116| loss: 0.35518 |  0:08:07s\n","epoch 117| loss: 0.35546 |  0:08:11s\n","epoch 118| loss: 0.35513 |  0:08:15s\n","epoch 119| loss: 0.35518 |  0:08:18s\n","epoch 120| loss: 0.35512 |  0:08:23s\n","epoch 121| loss: 0.3554  |  0:08:27s\n","epoch 122| loss: 0.35515 |  0:08:31s\n","epoch 123| loss: 0.35585 |  0:08:35s\n","epoch 124| loss: 0.35518 |  0:08:39s\n","epoch 125| loss: 0.35501 |  0:08:43s\n","epoch 126| loss: 0.35485 |  0:08:47s\n","epoch 127| loss: 0.35467 |  0:08:50s\n","epoch 128| loss: 0.35478 |  0:08:54s\n","epoch 129| loss: 0.35448 |  0:08:59s\n","epoch 130| loss: 0.35447 |  0:09:05s\n","epoch 131| loss: 0.35488 |  0:09:12s\n","epoch 132| loss: 0.35486 |  0:09:17s\n","epoch 133| loss: 0.35444 |  0:09:23s\n","epoch 134| loss: 0.35471 |  0:09:29s\n","epoch 135| loss: 0.35416 |  0:09:34s\n","epoch 136| loss: 0.35508 |  0:09:38s\n","epoch 137| loss: 0.35477 |  0:09:43s\n","epoch 138| loss: 0.35511 |  0:09:47s\n","epoch 139| loss: 0.35504 |  0:09:51s\n","epoch 140| loss: 0.35476 |  0:09:56s\n","epoch 141| loss: 0.35421 |  0:10:00s\n","epoch 142| loss: 0.35408 |  0:10:04s\n","epoch 143| loss: 0.35447 |  0:10:08s\n","epoch 144| loss: 0.35482 |  0:10:12s\n","epoch 145| loss: 0.35412 |  0:10:16s\n","epoch 146| loss: 0.35439 |  0:10:21s\n","epoch 147| loss: 0.35453 |  0:10:25s\n","epoch 148| loss: 0.35456 |  0:10:29s\n","epoch 149| loss: 0.3544  |  0:10:33s\n","epoch 150| loss: 0.35453 |  0:10:38s\n","epoch 151| loss: 0.3539  |  0:10:42s\n","epoch 152| loss: 0.3543  |  0:10:46s\n","epoch 153| loss: 0.35405 |  0:10:50s\n","epoch 154| loss: 0.35415 |  0:10:54s\n","epoch 155| loss: 0.35439 |  0:10:58s\n","epoch 156| loss: 0.35434 |  0:11:03s\n","epoch 157| loss: 0.35411 |  0:11:07s\n","epoch 158| loss: 0.35455 |  0:11:11s\n","epoch 159| loss: 0.35418 |  0:11:15s\n","epoch 160| loss: 0.35429 |  0:11:19s\n","epoch 161| loss: 0.3543  |  0:11:23s\n","epoch 162| loss: 0.354   |  0:11:27s\n","epoch 163| loss: 0.35363 |  0:11:31s\n","epoch 164| loss: 0.35426 |  0:11:36s\n","epoch 165| loss: 0.35358 |  0:11:40s\n","epoch 166| loss: 0.35399 |  0:11:44s\n","epoch 167| loss: 0.35379 |  0:11:48s\n","epoch 168| loss: 0.35329 |  0:11:52s\n","epoch 169| loss: 0.35345 |  0:11:55s\n","epoch 170| loss: 0.35339 |  0:11:59s\n","epoch 171| loss: 0.3536  |  0:12:03s\n","epoch 172| loss: 0.3543  |  0:12:07s\n","epoch 173| loss: 0.35351 |  0:12:11s\n","epoch 174| loss: 0.35404 |  0:12:15s\n","epoch 175| loss: 0.35367 |  0:12:19s\n","epoch 176| loss: 0.35396 |  0:12:23s\n","epoch 177| loss: 0.35334 |  0:12:27s\n","epoch 178| loss: 0.35551 |  0:12:31s\n","epoch 179| loss: 0.35454 |  0:12:35s\n","epoch 180| loss: 0.35447 |  0:12:39s\n","epoch 181| loss: 0.35526 |  0:12:43s\n","epoch 182| loss: 0.35398 |  0:12:47s\n","epoch 183| loss: 0.35382 |  0:12:51s\n","epoch 184| loss: 0.35388 |  0:12:55s\n","epoch 185| loss: 0.35345 |  0:12:59s\n","epoch 186| loss: 0.35327 |  0:13:03s\n","epoch 187| loss: 0.35333 |  0:13:07s\n","epoch 188| loss: 0.35349 |  0:13:11s\n","epoch 189| loss: 0.35409 |  0:13:15s\n","epoch 190| loss: 0.35706 |  0:13:19s\n","epoch 191| loss: 0.35668 |  0:13:23s\n","epoch 192| loss: 0.35581 |  0:13:27s\n","epoch 193| loss: 0.3563  |  0:13:31s\n","epoch 194| loss: 0.3541  |  0:13:35s\n","epoch 195| loss: 0.3538  |  0:13:39s\n","epoch 196| loss: 0.35429 |  0:13:43s\n","epoch 197| loss: 0.35394 |  0:13:47s\n","epoch 198| loss: 0.35395 |  0:13:51s\n","epoch 199| loss: 0.35363 |  0:13:56s\n"]}],"source":["# Chuẩn bị dữ liệu (giả sử X_train, y_train đã được chuẩn bị)\n","clf = TabNetClassifier()\n","clf.fit(\n","    X_train.values, y_train.values.ravel(),\n","    max_epochs=200,\n","    patience=20,\n","    batch_size=1024,\n","    virtual_batch_size=128\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nHEiOpwJpLDN"},"outputs":[],"source":["preds = clf.predict(X_test.values)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sGQN2VGTpLDN","outputId":"90f3be98-2135-4b7e-b251-4dadd664d990"},"outputs":[{"data":{"text/plain":["array([1, 1, 1, ..., 1, 1, 1])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FUxaxT1apLDN"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","report = classification_report(y_test.values.ravel(), preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBxN1vE5pLDN","outputId":"a3afaef1-d820-485f-f6f0-da1af81e29f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.79      0.51      0.62     16383\n","           1       0.86      0.96      0.90     51316\n","\n","    accuracy                           0.85     67699\n","   macro avg       0.82      0.73      0.76     67699\n","weighted avg       0.84      0.85      0.84     67699\n","\n"]}],"source":["print(report)"]}],"metadata":{"kernelspec":{"display_name":"3.10.11","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}